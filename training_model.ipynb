{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install keras_preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3-r4vg8pwOT",
        "outputId": "f17969e7-7a0b-4d6a-a3a0-d08e7033845b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BsciKP-TCQxU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Tensorflow Libraries\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,models\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "\n",
        "# System libraries\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "import random\n",
        "\n",
        "# Visualization Libraries\n",
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByuGiOjZDS1r",
        "outputId": "474f4acb-3b45-4dba-e4e5-8823d2dfdf33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-17 04:42:55--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-17 04:42:55 (108 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for our notebook\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BnRRmOK7C349"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "TARGET_SIZE = (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEN4cpffC6v0",
        "outputId": "d5579d5e-da05-4d48-cf3d-12e2253fd0c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 23 directories and 1 images in '/content/drive/MyDrive/aqua'.\n",
            "There are 0 directories and 72 images in '/content/drive/MyDrive/aqua/moorish idol'.\n",
            "There are 0 directories and 67 images in '/content/drive/MyDrive/aqua/fire fish'.\n",
            "There are 0 directories and 56 images in '/content/drive/MyDrive/aqua/mandarin fish'.\n",
            "There are 0 directories and 71 images in '/content/drive/MyDrive/aqua/emperor angelfish'.\n",
            "There are 0 directories and 78 images in '/content/drive/MyDrive/aqua/gemmatum tang'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/aqua/clown tang'.\n",
            "There are 0 directories and 66 images in '/content/drive/MyDrive/aqua/green chromis'.\n",
            "There are 0 directories and 71 images in '/content/drive/MyDrive/aqua/clown fish'.\n",
            "There are 0 directories and 73 images in '/content/drive/MyDrive/aqua/lion fish'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/aqua/blue damsel fish'.\n",
            "There are 0 directories and 75 images in '/content/drive/MyDrive/aqua/four stripped damsel fish'.\n",
            "There are 0 directories and 69 images in '/content/drive/MyDrive/aqua/racoon butterfly fish'.\n",
            "There are 0 directories and 57 images in '/content/drive/MyDrive/aqua/yellow longnose butterfly fish'.\n",
            "There are 0 directories and 71 images in '/content/drive/MyDrive/aqua/sailfin tang'.\n",
            "There are 0 directories and 58 images in '/content/drive/MyDrive/aqua/latticed butterfly fish'.\n",
            "There are 0 directories and 72 images in '/content/drive/MyDrive/aqua/convict tang'.\n",
            "There are 0 directories and 66 images in '/content/drive/MyDrive/aqua/tear drop butterfly fish'.\n",
            "There are 0 directories and 55 images in '/content/drive/MyDrive/aqua/six bar angelfish'.\n",
            "There are 0 directories and 73 images in '/content/drive/MyDrive/aqua/achilles tang'.\n",
            "There are 0 directories and 67 images in '/content/drive/MyDrive/aqua/regal angelfish'.\n",
            "There are 0 directories and 77 images in '/content/drive/MyDrive/aqua/regal tang'.\n",
            "There are 0 directories and 83 images in '/content/drive/MyDrive/aqua/pearscale butterfly fish'.\n",
            "There are 0 directories and 73 images in '/content/drive/MyDrive/aqua/copperband butterfly fish'.\n"
          ]
        }
      ],
      "source": [
        "dataset = \"/content/drive/MyDrive/aqua\"\n",
        "walk_through_dir(dataset);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "325rXWNoCjgS"
      },
      "outputs": [],
      "source": [
        "image_dir = Path(dataset)\n",
        "\n",
        "# Get filepaths and labels\n",
        "filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.png'))\n",
        "\n",
        "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
        "\n",
        "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
        "labels = pd.Series(labels, name='Label')\n",
        "\n",
        "# Concatenate filepaths and labels\n",
        "image_df = pd.concat([filepaths, labels], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LDL2UpZkDmHM"
      },
      "outputs": [],
      "source": [
        "train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "R6H6k6xZD-FM"
      },
      "outputs": [],
      "source": [
        "train_generator = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.resnet.preprocess_input,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "test_generator = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.resnet.preprocess_input,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3t2cInCD-c_",
        "outputId": "681fe41e-83e6-4400-c270-2f81f9ac3ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 797 validated image filenames belonging to 23 classes.\n",
            "Found 199 validated image filenames belonging to 23 classes.\n",
            "Found 250 validated image filenames belonging to 23 classes.\n"
          ]
        }
      ],
      "source": [
        "train_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=TARGET_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='training',\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "val_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=TARGET_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_images = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=TARGET_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OgmEpMOretJ-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRVX1CLmbmgA",
        "outputId": "8313196b-074d-4b7a-8ffb-3f1e6ba45754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 6s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 23)                47127     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,634,839\n",
            "Trainable params: 47,127\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(ResNet50(\n",
        "    include_top=False,\n",
        "    pooling='avg',\n",
        "    weights='imagenet'\n",
        "    ))\n",
        "\n",
        "model.add(Dense(23, activation='softmax'))\n",
        "\n",
        "model.layers[0].trainable = False\n",
        "\n",
        "model.summary()\n",
        "\n",
        "steps_per_epoch_training = len(train_images)\n",
        "steps_per_epoch_validation = len(val_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SIEYEs_igMgl"
      },
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')>0.999):\n",
        "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OANoEYhSeqEt",
        "outputId": "2fae3e0c-729a-4966-ba79-5196892db8b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-66ab7f7ae9b8>:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  fit_history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 620s 24s/step - loss: 2.4331 - accuracy: 0.3689 - val_loss: 1.2184 - val_accuracy: 0.7136\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.5682 - accuracy: 0.9310 - val_loss: 0.5383 - val_accuracy: 0.8995\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 5s 185ms/step - loss: 0.2209 - accuracy: 0.9837 - val_loss: 0.3819 - val_accuracy: 0.9548\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 5s 180ms/step - loss: 0.1275 - accuracy: 0.9975 - val_loss: 0.3257 - val_accuracy: 0.9397\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 1.0000\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "25/25 [==============================] - 4s 164ms/step - loss: 0.0854 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.9447\n"
          ]
        }
      ],
      "source": [
        "callbacks = myCallback()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "fit_history = model.fit_generator(\n",
        "    train_images,\n",
        "    steps_per_epoch=steps_per_epoch_training,\n",
        "    validation_steps=steps_per_epoch_validation,\n",
        "    epochs=10,\n",
        "    validation_data=val_images,\n",
        "    verbose=1,\n",
        "    callbacks=[callbacks]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqw2En_iENBC",
        "outputId": "3d859621-4ac2-43a8-db21-fcec31c62174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Test Loss: 0.36025\n",
            "Test Accuracy: 94.00%\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(test_images, verbose=0)\n",
        "\n",
        "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
        "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5bQBWKALlOGG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.resnet import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh1-zaL6k-Zq",
        "outputId": "19fa34b7-5340-47fa-ba68-ee3a55ad50e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Prepare the new image\n",
        "new_image_path = \"/content/drive/MyDrive/aquarium/fire fish/fire fish10.jpg\"\n",
        "\n",
        "# Load and preprocess the new image\n",
        "new_image = load_img(new_image_path, target_size=TARGET_SIZE)\n",
        "new_image = img_to_array(new_image)\n",
        "new_image = np.expand_dims(new_image, axis=0)\n",
        "new_image = preprocess_input(new_image)\n",
        "\n",
        "# Predict the new image\n",
        "predictions = model.predict(new_image)\n",
        "predicted_label_index = np.argmax(predictions)\n",
        "predicted_label_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TTFsfX8WvZ1-"
      },
      "outputs": [],
      "source": [
        "model.save(\"model.hdf5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
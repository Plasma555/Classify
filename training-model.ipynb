{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BsciKP-TCQxU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Tensorflow Libraries\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,models\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# System libraries\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "import random\n",
        "\n",
        "# Visualization Libraries\n",
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByuGiOjZDS1r",
        "outputId": "2cefe47d-780e-451c-d31c-2b0f288716b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-06-09 10:14:05--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-09 10:14:05 (91.3 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for our notebook\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BnRRmOK7C349"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "TARGET_SIZE = (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEN4cpffC6v0",
        "outputId": "d4d2d2b5-7b28-4a7f-a576-616c4baec518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 23 directories and 1 images in '/content/drive/MyDrive/aqua'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/aqua/clown tang'.\n",
            "There are 0 directories and 71 images in '/content/drive/MyDrive/aqua/clown fish'.\n",
            "There are 0 directories and 66 images in '/content/drive/MyDrive/aqua/green chromis'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/aqua/blue damsel fish'.\n",
            "There are 0 directories and 73 images in '/content/drive/MyDrive/aqua/lion fish'.\n",
            "There are 0 directories and 72 images in '/content/drive/MyDrive/aqua/moorish idol'.\n",
            "There are 0 directories and 56 images in '/content/drive/MyDrive/aqua/mandarin fish'.\n",
            "There are 0 directories and 67 images in '/content/drive/MyDrive/aqua/fire fish'.\n",
            "There are 0 directories and 78 images in '/content/drive/MyDrive/aqua/gemmatum tang'.\n",
            "There are 0 directories and 71 images in '/content/drive/MyDrive/aqua/emperor angelfish'.\n",
            "There are 0 directories and 73 images in '/content/drive/MyDrive/aqua/achilles tang'.\n",
            "There are 0 directories and 69 images in '/content/drive/MyDrive/aqua/racoon butterfly fish'.\n",
            "There are 0 directories and 58 images in '/content/drive/MyDrive/aqua/latticed butterfly fish'.\n",
            "There are 0 directories and 71 images in '/content/drive/MyDrive/aqua/sailfin tang'.\n",
            "There are 0 directories and 57 images in '/content/drive/MyDrive/aqua/yellow longnose butterfly fish'.\n",
            "There are 0 directories and 55 images in '/content/drive/MyDrive/aqua/six bar angelfish'.\n",
            "There are 0 directories and 75 images in '/content/drive/MyDrive/aqua/four stripped damsel fish'.\n",
            "There are 0 directories and 66 images in '/content/drive/MyDrive/aqua/tear drop butterfly fish'.\n",
            "There are 0 directories and 67 images in '/content/drive/MyDrive/aqua/regal angelfish'.\n",
            "There are 0 directories and 72 images in '/content/drive/MyDrive/aqua/convict tang'.\n",
            "There are 0 directories and 77 images in '/content/drive/MyDrive/aqua/regal tang'.\n",
            "There are 0 directories and 73 images in '/content/drive/MyDrive/aqua/copperband butterfly fish'.\n",
            "There are 0 directories and 83 images in '/content/drive/MyDrive/aqua/pearscale butterfly fish'.\n"
          ]
        }
      ],
      "source": [
        "dataset = \"/content/drive/MyDrive/aqua\"\n",
        "walk_through_dir(dataset);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "325rXWNoCjgS"
      },
      "outputs": [],
      "source": [
        "image_dir = Path(dataset)\n",
        "\n",
        "# Get filepaths and labels\n",
        "filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.png'))\n",
        "\n",
        "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
        "\n",
        "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
        "labels = pd.Series(labels, name='Label')\n",
        "\n",
        "# Concatenate filepaths and labels\n",
        "image_df = pd.concat([filepaths, labels], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wjdO0hb9DbE-"
      },
      "outputs": [],
      "source": [
        "def compute_ela_cv(path, quality):\n",
        "    temp_filename = 'temp_file_name.jpeg'\n",
        "    SCALE = 15\n",
        "    orig_img = cv2.imread(path)\n",
        "    orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    cv2.imwrite(temp_filename, orig_img, [cv2.IMWRITE_JPEG_QUALITY, quality])\n",
        "\n",
        "    # read compressed image\n",
        "    compressed_img = cv2.imread(temp_filename)\n",
        "\n",
        "    # get absolute difference between img1 and img2 and multiply by scale\n",
        "    diff = SCALE * cv2.absdiff(orig_img, compressed_img)\n",
        "    return diff\n",
        "\n",
        "\n",
        "def convert_to_ela_image(path, quality):\n",
        "    temp_filename = 'temp_file_name.jpeg'\n",
        "    ela_filename = 'temp_ela.png'\n",
        "    image = Image.open(path).convert('RGB')\n",
        "    image.save(temp_filename, 'JPEG', quality = quality)\n",
        "    temp_image = Image.open(temp_filename)\n",
        "\n",
        "    ela_image = ImageChops.difference(image, temp_image)\n",
        "\n",
        "    extrema = ela_image.getextrema()\n",
        "    max_diff = max([ex[1] for ex in extrema])\n",
        "    if max_diff == 0:\n",
        "        max_diff = 1\n",
        "\n",
        "    scale = 255.0 / max_diff\n",
        "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
        "    \n",
        "    return ela_image\n",
        "\n",
        "\n",
        "def random_sample(path, extension=None):\n",
        "    if extension:\n",
        "        items = Path(path).glob(f'*.{extension}')\n",
        "    else:\n",
        "        items = Path(path).glob(f'*')\n",
        "        \n",
        "    items = list(items)\n",
        "        \n",
        "    p = random.choice(items)\n",
        "    return p.as_posix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LDL2UpZkDmHM"
      },
      "outputs": [],
      "source": [
        "train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "R6H6k6xZD-FM"
      },
      "outputs": [],
      "source": [
        "train_generator = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "test_generator = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3t2cInCD-c_",
        "outputId": "4d5b909b-c235-43b0-bef9-ae699b98f2c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 797 validated image filenames belonging to 23 classes.\n",
            "Found 199 validated image filenames belonging to 23 classes.\n",
            "Found 250 validated image filenames belonging to 23 classes.\n"
          ]
        }
      ],
      "source": [
        "train_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=TARGET_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='training',\n",
        "    \n",
        ")\n",
        "\n",
        "\n",
        "val_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=TARGET_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_images = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=TARGET_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OgmEpMOretJ-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRVX1CLmbmgA",
        "outputId": "e799f584-0a3a-4a70-d9d9-b010451359d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 6s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 23)                47127     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,634,839\n",
            "Trainable params: 47,127\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(ResNet50(\n",
        "    include_top=False,\n",
        "    pooling='avg',\n",
        "    weights='imagenet'\n",
        "    ))\n",
        "\n",
        "model.add(Dense(23, activation='softmax'))\n",
        "\n",
        "model.layers[0].trainable = False \n",
        "\n",
        "model.summary()\n",
        "\n",
        "steps_per_epoch_training = len(train_images)\n",
        "steps_per_epoch_validation = len(val_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SIEYEs_igMgl"
      },
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')>0.999):\n",
        "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OANoEYhSeqEt",
        "outputId": "918680f5-c6a0-4fe5-a01c-6d783a955e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-21-66ab7f7ae9b8>:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  fit_history = model.fit_generator(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 8s 192ms/step - loss: 0.0924 - accuracy: 0.9975 - val_loss: 0.2758 - val_accuracy: 0.9196\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 1.0000\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "25/25 [==============================] - 5s 180ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9548\n"
          ]
        }
      ],
      "source": [
        "callbacks = myCallback()\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "fit_history = model.fit_generator(\n",
        "    train_images,\n",
        "    steps_per_epoch=steps_per_epoch_training,\n",
        "    validation_steps=steps_per_epoch_validation,\n",
        "    epochs=10,\n",
        "    validation_data=val_images,\n",
        "    verbose=1,\n",
        "    callbacks=[callbacks]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqw2En_iENBC",
        "outputId": "bd7819c9-7ea8-42ce-b1e7-5e1b4aeffcbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Test Loss: 0.27667\n",
            "Test Accuracy: 92.80%\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(test_images, verbose=0)\n",
        "\n",
        "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
        "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5bQBWKALlOGG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh1-zaL6k-Zq",
        "outputId": "563a81a1-74f1-49ea-ecf2-659cd23665e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Prepare the new image\n",
        "new_image_path = \"/content/drive/MyDrive/tit/images (4).jpeg\"\n",
        "\n",
        "# Load and preprocess the new image\n",
        "new_image = load_img(new_image_path, target_size=TARGET_SIZE)\n",
        "new_image = img_to_array(new_image)\n",
        "new_image = np.expand_dims(new_image, axis=0)\n",
        "new_image = preprocess_input(new_image)\n",
        "\n",
        "# Predict the new image\n",
        "predictions = model.predict(new_image)\n",
        "predicted_label_index = np.argmax(predictions)\n",
        "predicted_label_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "TTFsfX8WvZ1-"
      },
      "outputs": [],
      "source": [
        "model.save(\"model.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcQiyZAIvc7Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
